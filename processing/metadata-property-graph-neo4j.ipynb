{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%capture\n",
    "!pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import pardir\n",
    "from os.path import join\n",
    "\n",
    "from utils.literature import get_files, get_document_title, get_authors, get_ref_entires, DataLoader, is_english\n",
    "from utils.processing import create_chunks\n",
    "from utils.metadata import CORDMetadata\n",
    "from utils.grid.grid import GridLookup\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "from multiprocessing.pool import Pool\n",
    "from tqdm._tqdm_notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = ('neo4j', 'password')\n",
    "address = f'bolt://localhost:7687'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new(tx, title, doc_id, author, institution, journal):\n",
    "    tx.run(\"MERGE (a:Document {title: $title, doc_id: $doc_id})\"\n",
    "           \"MERGE (b:Author {name: $author})\"\n",
    "           \"MERGE (c:Institution {name: $institution_name})\"\n",
    "           \"MERGE (d:Journal {name: $journal})\"\n",
    "           \"MERGE (e:Country {name: $country, code: $code})\"\n",
    "           \"MERGE (b)-[:WORKS_FOR]->(c)\"\n",
    "           \"MERGE (c)-[:EMPLOYED]->(b)\"\n",
    "           \"MERGE (a)-[:WROTE]->(b)\"\n",
    "           \"MERGE (b)-[:WRITTEN_BY]->(a)\"\n",
    "           \"MERGE (c)-[:LOCATED_IN]->(e)\"\n",
    "           \"MERGE (e)-[:LOCATES]->(c)\"\n",
    "           \"MERGE (a)-[:PUBLISHED_IN]->(d)\"\n",
    "           \"MERGE (d)-[:PUBLISHED]->(a)\",\n",
    "           title=title, doc_id=doc_id, author=author, institution_name=institution['Name'], \n",
    "           country = institution['Country'], code=institution['Code'], journal=journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = join(pardir, 'dataset')\n",
    "files = get_files(root_dir)\n",
    "metadata_lookup = CORDMetadata()\n",
    "grid_lookup = GridLookup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "undefined = {\n",
    "    'Name': 'undefined', \n",
    "    'Country': 'undefined', \n",
    "    'Code': 'undefined'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(args):\n",
    "    with GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"password\"), encrypted=False) as driver:        \n",
    "        #iterate over all documents in chunk\n",
    "        for fpath, doc_id in args:\n",
    "            doc_id = int(doc_id)\n",
    "            data_loader = DataLoader(fpath, grid_lookup)\n",
    "\n",
    "            doc_title = get_document_title(fpath, data_loader)\n",
    "            sha = data_loader.get_paper_id()\n",
    "            journal = metadata_lookup.get_journal(sha)\n",
    "            #database should only contain english documents with an valid document title\n",
    "            if doc_title == '' or not is_english(doc_title):\n",
    "                continue\n",
    "\n",
    "            authors = get_authors(fpath, data_loader)\n",
    "            for author, institution in authors:\n",
    "                if author is None: continue\n",
    "                institution = institution if institution is not None else undefined\n",
    "                journal = journal if journal is not None and journal != 'nan' else 'undefined'\n",
    "                with driver.session() as session:\n",
    "                    session.write_transaction(add_new, doc_title, doc_id, author, institution, journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "processing 384 of 385\n"
    }
   ],
   "source": [
    "chunks = create_chunks(files)\n",
    "\n",
    "#TODO: Fix error with multithreading to allow parallel processing of chunks\n",
    "for i, chunk in enumerate(chunks):\n",
    "    clear_output(wait=True)\n",
    "    print(f'processing {i} of {len(chunks)}')\n",
    "    process_chunk(chunk)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitbaseconda685979d1612e4539ab4b182671d44102",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}