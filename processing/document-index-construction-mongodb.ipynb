{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pymongo\n",
    "!pip install pycld2\n",
    "!pip install pandas\n",
    "!pip install nltk\n",
    "!pip install redis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mongodb caching\n",
    "\n",
    "start redis server with the followin configuration in order to speed up the inverted index construction:\n",
    "\n",
    "```\n",
    "redis-server --maxmemory 10GB --maxmemory-policy allkeys-lfu --port 27018\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import string\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import pycld2 as cld2\n",
    "\n",
    "from multiprocessing.pool import Pool\n",
    "from tqdm._tqdm_notebook import tqdm\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from os import getcwd, pardir\n",
    "from os.path import join, basename\n",
    "\n",
    "from utils.literature import DataLoader, get_document_title, is_english, get_section, get_sections, get_files, get_authors\n",
    "from utils.preprocessing import NLPPipeline, Tokenizer, Stemmer, ToLowercase, Lemmatizer, StopwordRemover, CitationRemover, SymbolRemover, ContentInBracketsRemover\n",
    "from utils.grid.grid import GridLookup\n",
    "from glob import glob\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer #TODO: Try lemmatizer instead of stemmer\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient as DBClient\n",
    "\n",
    "import redis\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specification of the document paths\n",
    "\n",
    "- download from: [Kaggle](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge)\n",
    "- extract folder content to `{ProjectDir}/dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = join(pardir, 'dataset')\n",
    "files = get_files(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the document index\n",
    "\n",
    "Each document gets stored in the document_index collection with the following layout: \n",
    "```json\n",
    "{\n",
    "    _id: ..., \n",
    "    document_title: ...,\n",
    "    authors: [\n",
    "        ...,\n",
    "        ...,\n",
    "        ...\n",
    "    ],\n",
    "    abstract: ...\n",
    "}\n",
    "```\n",
    "\n",
    "## Building the inverted index\n",
    "\n",
    "```json\n",
    "{\n",
    "    'stem': ...,\n",
    "    'doc_ids': [\n",
    "        {\n",
    "            {'doc_id': ..., \n",
    "             'count': {\n",
    "                 'title': ...,\n",
    "                 'abstract': ...,\n",
    "                 'body_text': ...}\n",
    "             },\n",
    "             {'doc_id': ..., \n",
    "             'count': {\n",
    "                 'title': ...,\n",
    "                 'abstract': ...,\n",
    "                 'body_text': ...}\n",
    "             }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with DBClient('localhost', 27017, w=0) as client:\n",
    "    db = client['covid_19']\n",
    "    inverted_index_collection = db['inverted_index']\n",
    "    inverted_index_collection.create_index([(\"doc_ids\", pymongo.ASCENDING)], background=True, name='doc_ids')\n",
    "    inverted_index_collection.create_index([(\"doc_ids.doc_id\", pymongo.ASCENDING)], background=True, name='doc_ids.doc_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = NLPPipeline([\n",
    "    ToLowercase(),\n",
    "    CitationRemover(),\n",
    "    ContentInBracketsRemover(),\n",
    "    Tokenizer(),\n",
    "    SymbolRemover(),\n",
    "    StopwordRemover(),\n",
    "    Stemmer()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_post(stem, doc_id, count_object):\n",
    "    return {'_id': stem, 'doc_ids': [{'doc_id': doc_id, 'count': count_object}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_count_object(section, count=1):\n",
    "    if section is 'title': return {'title': count, 'abstract': 0, 'body_text': 0}\n",
    "    elif section is 'abstract': return {'title': 0, 'abstract': count, 'body_text': 0}\n",
    "    elif section is 'body_text': return {'title': 0, 'abstract': 0, 'body_text': count}\n",
    "    else: raise Exception('Invalid section')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_document_index(doc_id, document_title, document_index_collection):\n",
    "    doc_id_entry = document_index_collection.find({'_id': doc_id}).limit(1)\n",
    "    if doc_id_entry.count() == 0:\n",
    "        document_index_collection.insert_one({'_id': doc_id, 'document_title': document_title})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_document_index_object(doc_id, document_title, authors, abstract):\n",
    "    return {'_id': doc_id, 'document_title': document_title, 'abstract': abstract, 'authors': [{'author': author, 'institution': institution['Name'] if institution != None else 'undefined'} for author, institution in authors]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_cache_stem(stem, redis_cache):\n",
    "    redis_cache.set(stem, 'T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_cache_doc_id(stem, doc_id, redis_cache):\n",
    "    redis_cache.set(f'stem:{stem}_doc_id:{doc_id}', 'T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_cache_document(title, redis_cache):\n",
    "    redis_cache.set(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_document_existent(title, redis_cache):\n",
    "    return True if redis_cache.get(title) else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_stem_existent(stem, inverted_index_collection, redis_cache):\n",
    "    result = redis_cache.get(stem)\n",
    "    if result: return True\n",
    "\n",
    "    result = inverted_index_collection.find({'_id': stem}).limit(1)\n",
    "    return True if result.count() > 0 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_doc_id_existent(stem, doc_id, inverted_index_collection, redis_cache):\n",
    "    result = redis_cache.get(f'stem:{stem}_doc_id:{doc_id}')\n",
    "    if result: return True\n",
    "    \n",
    "    result = inverted_index_collection.find(\n",
    "                {'_id': stem, \n",
    "                'doc_ids': {'$elemMatch': {'doc_id': doc_id}}}).limit(1)\n",
    "    return True if result.count() > 0 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_inverted_index(doc_id, stemmed_tokens, section, inverted_index_collection, redis_cache):\n",
    "    #update inverted index\n",
    "    for stem, count in stemmed_tokens.items():\n",
    "        has_stem = is_stem_existent(stem, inverted_index_collection, redis_cache)\n",
    "        if has_stem:\n",
    "            #try to find current document id in stem entry\n",
    "            has_doc_id = is_doc_id_existent(stem, doc_id, inverted_index_collection, redis_cache)\n",
    "            if has_doc_id:\n",
    "                # update occurrence of stem in document section\n",
    "                inverted_index_collection.update(\n",
    "                    {'_id': stem, \n",
    "                    'doc_ids': {'$elemMatch': {'doc_id': doc_id}}},\n",
    "                    {'$inc': {f'doc_ids.$.count.{section}': count}})\n",
    "            else:\n",
    "                # add document id\n",
    "                update_cache_doc_id(stem, doc_id, redis_cache)\n",
    "                inverted_index_collection.update(\n",
    "                    {'_id': stem},\n",
    "                    {'$push': {'doc_ids': {'doc_id': doc_id, 'count': create_count_object(section, count)}}})\n",
    "        else:\n",
    "            update_cache_stem(stem, redis_cache)\n",
    "            post = create_post(stem, doc_id, create_count_object(section, count))\n",
    "            inverted_index_collection.insert_one(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lookup = GridLookup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(args, update_doc_idx=True, update_inv_indx=True):\n",
    "    with DBClient('localhost', 27017, w=0) as client:\n",
    "        with redis.Redis(host='localhost', port=27018) as redis_cache:\n",
    "            #open a connection to the database\n",
    "            db = client['covid_19']\n",
    "            document_index_collection = db['document_index']\n",
    "            inverted_index_collection = db['inverted_index']\n",
    "\n",
    "            document_objects = []\n",
    "            \n",
    "            #iterate over all documents in chunk\n",
    "            for fpath, doc_id in args:\n",
    "                doc_id = int(doc_id)\n",
    "                data_loader = DataLoader(fpath, grid_lookup) #dummy object for grid lookup\n",
    "\n",
    "                doc_title = get_document_title(fpath, data_loader)\n",
    "                #doc_exists = is_document_existent(doc_title)\n",
    "                   # if doc_exists:\n",
    "                        #continue\n",
    "\n",
    "                #database should only contain english documents with an valid document title\n",
    "                if doc_title == '' or not is_english(doc_title):\n",
    "                    continue\n",
    "\n",
    "                if update_doc_idx:\n",
    "                    abstract = get_section(fpath,'abstract', data_loader)[:500] + \"...\"\n",
    "                    authors = get_authors(fpath, data_loader, plausibility_check=True, clean_names=True, normalize_names=False)\n",
    "\n",
    "                    document_index_collection.insert_one(create_document_index_object(doc_id, doc_title, authors, abstract))\n",
    "                    #update_cache_document(doc_title, redis_cache)\n",
    "\n",
    "\n",
    "                #if not update_inverted_index:\n",
    "                #    continue\n",
    "                #\n",
    "                #for section in get_sections():\n",
    "                #    text = get_section(fpath, section, dl=data_loader)\n",
    "                #    stemmed_tokens = pipeline.transform(text)\n",
    "                #    stemmed_tokens_reduced = Counter(stemmed_tokens)\n",
    "                #    update_inverted_index(doc_id, stemmed_tokens_reduced, section, inverted_index_collection, redis_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunks(files, chunk_size=128):\n",
    "    doc_ids = list(range(len(files)))\n",
    "    chunks = list()\n",
    "    for i in range(0, len(files), chunk_size):\n",
    "        indices = np.array(doc_ids[i: min(i+chunk_size, len(files))])\n",
    "        chunks.append(list(zip(\n",
    "            files[i: min(i+chunk_size, len(files))], \n",
    "            doc_ids[i: min(i+chunk_size, len(files))])))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=385.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2310cdde15d843da94ae0936addcaf40"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Process ForkPoolWorker-16:\nTraceback (most recent call last):\nProcess ForkPoolWorker-15:\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\nTraceback (most recent call last):\nProcess ForkPoolWorker-9:\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\nProcess ForkPoolWorker-5:\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\nTraceback (most recent call last):\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"<ipython-input-16-a0265bfe12a2>\", line 27, in process_chunk\n    authors = get_authors(fpath, data_loader)\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\nProcess ForkPoolWorker-1:\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/literature.py\", line 182, in get_authors\n    return dl.get_authors(plausibility_check, clean_names, normalize_names)\n  File \"<ipython-input-16-a0265bfe12a2>\", line 27, in process_chunk\n    authors = get_authors(fpath, data_loader)\nProcess ForkPoolWorker-14:\nProcess ForkPoolWorker-4:\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/literature.py\", line 92, in get_authors\n    plausibility_check=plausibility_check)\nProcess ForkPoolWorker-10:\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/literature.py\", line 77, in __parse_institution\n    is_institution = self.grid_lookup.get_institution(institution_raw) != None\nTraceback (most recent call last):\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/grid/grid.py\", line 156, in get_institution\n    matched_name = self.__fuzzy_match_institution(name)\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/grid/grid.py\", line 144, in __fuzzy_match_institution\n    result = self.fuzzy_set.get(name)\n  File \"<ipython-input-16-a0265bfe12a2>\", line 27, in process_chunk\n    authors = get_authors(fpath, data_loader)\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/literature.py\", line 182, in get_authors\n    return dl.get_authors(plausibility_check, clean_names, normalize_names)\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\nTraceback (most recent call last):\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/literature.py\", line 92, in get_authors\n    plausibility_check=plausibility_check)\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/literature.py\", line 182, in get_authors\n    return dl.get_authors(plausibility_check, clean_names, normalize_names)\nKeyboardInterrupt\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/literature.py\", line 77, in __parse_institution\n    is_institution = self.grid_lookup.get_institution(institution_raw) != None\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/literature.py\", line 92, in get_authors\n    plausibility_check=plausibility_check)\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"<ipython-input-16-a0265bfe12a2>\", line 27, in process_chunk\n    authors = get_authors(fpath, data_loader)\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/literature.py\", line 182, in get_authors\n    return dl.get_authors(plausibility_check, clean_names, normalize_names)\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/literature.py\", line 92, in get_authors\n    plausibility_check=plausibility_check)\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/grid/grid.py\", line 156, in get_institution\n    matched_name = self.__fuzzy_match_institution(name)\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/grid/grid.py\", line 156, in get_institution\n    matched_name = self.__fuzzy_match_institution(name)\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/literature.py\", line 77, in __parse_institution\n    is_institution = self.grid_lookup.get_institution(institution_raw) != None\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/grid/grid.py\", line 156, in get_institution\n    matched_name = self.__fuzzy_match_institution(name)\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/grid/grid.py\", line 144, in __fuzzy_match_institution\n    result = self.fuzzy_set.get(name)\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/grid/grid.py\", line 144, in __fuzzy_match_institution\n    result = self.fuzzy_set.get(name)\nKeyboardInterrupt\nKeyboardInterrupt\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/literature.py\", line 77, in __parse_institution\n    is_institution = self.grid_lookup.get_institution(institution_raw) != None\nTraceback (most recent call last):\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/grid/grid.py\", line 144, in __fuzzy_match_institution\n    result = self.fuzzy_set.get(name)\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"<ipython-input-16-a0265bfe12a2>\", line 27, in process_chunk\n    authors = get_authors(fpath, data_loader)\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\nProcess ForkPoolWorker-13:\nTraceback (most recent call last):\nKeyboardInterrupt\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\n  File \"<ipython-input-16-a0265bfe12a2>\", line 27, in process_chunk\n    authors = get_authors(fpath, data_loader)\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/literature.py\", line 182, in get_authors\n    return dl.get_authors(plausibility_check, clean_names, normalize_names)\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/literature.py\", line 92, in get_authors\n    plausibility_check=plausibility_check)\nProcess ForkPoolWorker-8:\n  File \"<ipython-input-16-a0265bfe12a2>\", line 27, in process_chunk\n    authors = get_authors(fpath, data_loader)\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/literature.py\", line 77, in __parse_institution\n    is_institution = self.grid_lookup.get_institution(institution_raw) != None\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/literature.py\", line 182, in get_authors\n    return dl.get_authors(plausibility_check, clean_names, normalize_names)\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n    self._target(*self._args, **self._kwargs)\nTraceback (most recent call last):\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/literature.py\", line 182, in get_authors\n    return dl.get_authors(plausibility_check, clean_names, normalize_names)\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\nProcess ForkPoolWorker-3:\nTraceback (most recent call last):\n  File \"/home/tobias/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n    self.run()\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/literature.py\", line 92, in get_authors\n    plausibility_check=plausibility_check)\nProcess ForkPoolWorker-7:\n  File \"/home/tobias/Desktop/covid19-search/processing/utils/grid/grid.py\", line 156, in get_institution\n    matched_name = self.__fuzzy_match_institution(name)\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e55442d3e29d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    735\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pool = Pool()\n",
    "chunks = create_chunks(files)\n",
    "\n",
    "for _ in tqdm(pool.imap_unordered(process_chunk, chunks), total=len(chunks)):\n",
    "    pass\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance monitoring\n",
    "\n",
    "~ 20 0000 documents in database\n",
    "\n",
    "Backlog: automatische Übersetzung\n",
    "Neo4j semantic web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "%%timeit -n 100\n",
    "with DBClient('localhost', 27017, w=0) as client:\n",
    "    #open a connection to the database\n",
    "    db = client['covid_19']\n",
    "    document_index_collection = db['document_index']\n",
    "    inverted_index_collection = db['inverted_index']\n",
    "```\n",
    "\n",
    "785 µs ± 46.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "%%timeit -n 100\n",
    "data_loader = DataLoader(files[0])\n",
    "doc_title = get_document_title(files[0], data_loader)\n",
    "```\n",
    "\n",
    "496 µs ± 27.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-74acc682410d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-n 100'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_loader = DataLoader(files[0])\\nabstract = get_section(files[0], 'abstract', data_loader)\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2360\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/tobias/anaconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1162\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0mall_runs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0mworst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/timeit.py\u001b[0m in \u001b[0;36mrepeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;32m~/Desktop/covid19-search/processing/utils/literature.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, grid_lookup)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_lookup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_lookup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_lookup\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgrid_lookup\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mGridLookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/covid19-search/processing/utils/grid/grid.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, use_fuzzy_matching)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_fuzzy_matching\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuzzy_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFuzzySet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuzzy_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/covid19-search/processing/utils/grid/grid.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_fuzzy_matching\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuzzy_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFuzzySet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuzzy_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%timeit -n 100\n",
    "data_loader = DataLoader(files[0])\n",
    "abstract = get_section(files[0], 'abstract', data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "data_loader = DataLoader(files[0])\n",
    "abstract = get_section(files[0], 'abstract', data_loader)\n",
    "\n",
    "%%timeit -n 100\n",
    "is_english(abstract)\n",
    "```\n",
    "\n",
    "48.8 µs ± 1.02 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "%%timeit -n 100\n",
    "pipeline.transform(doc_title)\n",
    "```\n",
    "\n",
    "1.35 ms ± 43.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "%%timeit\n",
    "inverted_index_collection.find({'_id': 'detect'}).limit(1).count()\n",
    "```\n",
    "\n",
    "1.35 ms ± 43.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "%%timeit\n",
    "doc_id_object = inverted_index_collection.find(\n",
    "                {'_id': 'detect', \n",
    "                'doc_ids': {'$elemMatch': {'doc_id': 312}}}).limit(1).count()\n",
    "```\n",
    "\n",
    "1.35 ms ± 43.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "import uuid\n",
    "\n",
    "%%timeit\n",
    "post = create_post(uuid.uuid4(), -1, count_object['abstract'])\n",
    "inverted_index_collection.insert_one(post)\n",
    "```\n",
    "\n",
    "98.7 µs ± 122 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "%%timeit\n",
    "inverted_index_collection.update(\n",
    "        {'_id': 'testtoken', \n",
    "        'doc_ids': {'$elemMatch': {'doc_id': -1}}},\n",
    "        {'$inc': {f'doc_ids.$.count.abstract': 1}})\n",
    "```\n",
    "\n",
    "99.2 µs ± 999 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "%%timeit -n 1000\n",
    "inverted_index_collection.update(\n",
    "                    {'_id': 'testtoken'},\n",
    "                    {'$push': {'doc_ids': {'doc_id': -2, 'count': count_object['abstract']}}})\n",
    "```\n",
    "\n",
    "99.2 µs ± 999 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.098+ 0.099+ 0.092) /3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timings_db = pd.DataFrame()\n",
    "\n",
    "timings_db['action'] = [\"Verbindungsaufbau\", \"Lesezugriff\", \"Schreibzugriff\"]\n",
    "timings_db['timing'] = [0.785, 1.35, 0.096]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(df):\n",
    "  groups = df.groupby('action')\n",
    "  for i, (name,group) in enumerate(groups):\n",
    "    plt.bar(name, group['timing'], label=name, align='center', color=cm.Blues(i*30 + 100))\n",
    "\n",
    "  ax = plt.gca()\n",
    "  #ax.get_xaxis().set_visible(False)\n",
    "  ax.set_ylabel('Durchschnittliche Laufzeit in ms')\n",
    "  ax.grid(linestyle=':')\n",
    "  #plt.legend()\n",
    "  fig = plt.gcf()\n",
    "  fig.savefig('laufzeit-mongo.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 7, 4\n",
    "f(timings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timings_proc = pd.DataFrame()\n",
    "\n",
    "timings_proc['action'] = [\"Laden der Datei\", \"Extraktion der Autoren\", \"Extraktion des Textsektionen\" ,\"Verarbeitungspipeline\"]\n",
    "timings_proc['timing'] = [0.5, 0.0, 0.272, 1.35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 7, 4\n",
    "f(timings_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}